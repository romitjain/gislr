{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c494ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.visualize import get_pts_to_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304e1b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = pd.read_parquet(\"./data/raw/train_landmark_files/16069/100015657.parquet\")\n",
    "\n",
    "tmp = img[(img.frame == 107) | (img.frame == 106)]\n",
    "data = np.array(tmp[[\"x\", \"y\", \"z\"]]).reshape(2, 543, 3)\n",
    "\n",
    "print(img.loc[img.x.isna()].query('frame == 103').type.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4af80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.query('frame == 106 and type == \"left_hand\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b154b189",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = get_pts_to_img(data[1])\n",
    "plt.imshow(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4633d222",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.augmentations import aug_hflip, KeypointsIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431e3471",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf = np.load(\"./data/generated/np_landmarks/100015657.npy\")\n",
    "ndf = ndf[5:7, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcc6cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pts_rh, y_pts_rh, z_pts_rh = ndf[:, KeypointsIndex.right_hand_x_index], ndf[:, KeypointsIndex.right_hand_y_index], ndf[:, KeypointsIndex.right_hand_z_index]\n",
    "x_pts_lh, y_pts_lh, z_pts_lh = ndf[:, KeypointsIndex.left_hand_x_index], ndf[:,KeypointsIndex.right_hand_y_index], ndf[:, KeypointsIndex.left_hand_z_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945a9c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pts_lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e357a2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - x_pts_lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42065bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf[:, KeypointsIndex.right_hand_x_index] = 1 - x_pts_lh\n",
    "ndf[:, KeypointsIndex.left_hand_x_index] = 1 - x_pts_rh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2841fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf[:, KeypointsIndex.left_hand_x_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e61380",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pts_rh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7da3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for x in range(IndexLabels.right_hand[0], 3*IndexLabels.right_hand[1], 3):\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09c3719",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pts_rh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1fe700",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pts_rh, x_pts_lh = aug_hflip(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a9ce18",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf = np.load(\"./data/generated/np_landmarks/100015657.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4129366",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[:, IndexLabels.right_hand[0]: IndexLabels.right_hand[1]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f48f9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - data[:, IndexLabels.left_hand[0]: IndexLabels.left_hand[1]][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed89ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[:, IndexLabels.right_hand[0]: IndexLabels.right_hand[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bee0d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pts_rh = x_pts_lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc643b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lips = set()\n",
    "for elem in mp.solutions.face_mesh_connections.FACEMESH_LIPS:\n",
    "    lips.add(elem[0])\n",
    "    lips.add(elem[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385e6a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7f1306",
   "metadata": {},
   "source": [
    "Albumentations EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd581119",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import mediapipe as mp\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "\n",
    "TOTAL_PTS = 543"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a357b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_frames = np.load(\"./data/generated/np_landmarks/100015657.npy\")\n",
    "all_frames = np.resize(all_frames, (all_frames.shape[0], TOTAL_PTS, 3))\n",
    "all_frames = np.where(np.isnan(all_frames), 0, all_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fbb904",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_transform(transform, frame_keypoints):\n",
    "    xy = [(np.max((pt[0], 0)), np.max((pt[1], 0))) for pt in frame_keypoints]\n",
    "\n",
    "    augmented = transform(\n",
    "        image=np.zeros((256, 256)),\n",
    "        keypoints=xy,\n",
    "        keypoint_params=A.KeypointParams(format='xy', remove_invisible=False)\n",
    "    )\n",
    "    \n",
    "    augmented_keypoints = np.array([[kp[0], kp[1]] for kp in augmented['keypoints']])\n",
    "    \n",
    "    # Appending z axis data to the augmented dataset\n",
    "    augmented_keypoints = np.stack(\n",
    "        [augmented_keypoints[:, 0], augmented_keypoints[:, 1], frame_keypoints[:, 2]],\n",
    "        axis=-1\n",
    "    )\n",
    "    \n",
    "    return augmented, augmented_keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f5210f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = A.Compose([\n",
    "#         A.Rotate(limit=10, p=1),\n",
    "#         A.RandomCrop(width=128, height=128),\n",
    "        A.RandomScale(p=1, scale_limit=(-1, 0.3)),\n",
    "#         A.ShiftScaleRotate(p=1.0, shift_limit=10, border_mode=cv2.BORDER_CONSTANT, value=0),\n",
    "#         A.RandomShear(p=1, shear_limit=0.2),\n",
    "#         A.Affine(\n",
    "#             scale=(-1, 0.5), keep_ratio=True, \n",
    "#             translate_percent=0.5,\n",
    "#             rotate=10,\n",
    "#             p=1.0,\n",
    "#             shear=45,\n",
    "#             mode=cv2.BORDER_CONSTANT\n",
    "#         )\n",
    "    ],\n",
    "    keypoint_params=A.KeypointParams(format='xy')\n",
    ")\n",
    "\n",
    "frame_keypoints = all_frames[0]\n",
    "xy = [(np.max((pt[0], 0)), np.max((pt[1], 0))) for pt in frame_keypoints]\n",
    "\n",
    "augmented = transform(\n",
    "    image=np.zeros((256, 256)),\n",
    "    keypoints=xy,\n",
    "    keypoint_params=A.KeypointParams(format='xy', remove_invisible=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a52a298",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_frames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed1447b",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented[\"keypoints\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed368cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_keypoints = np.array([[kp[0], kp[1]] for kp in augmented['keypoints']])\n",
    "\n",
    "# Appending z axis data to the augmented dataset\n",
    "augmented_keypoints = np.stack(\n",
    "    [augmented_keypoints[:, 0], augmented_keypoints[:, 1], frame_keypoints[:, 2]],\n",
    "    axis=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f62964",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = A.ReplayCompose([\n",
    "        # A.HorizontalFlip(p=1),\n",
    "        A.Rotate(limit=10, p=1),\n",
    "#         A.RandomScale(p=1, scale_limit=(-1, 0.3)),\n",
    "        # A.RandomTranslate(p=0.2, translate_limit=(-0.2, 0.2)),\n",
    "        # A.RandomShear(p=1, shear_limit=0.2),\n",
    "        # A.RandomRotate90(p=0.2),\n",
    "    ],\n",
    "    keypoint_params=A.KeypointParams(format='xy')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059dba9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88de21ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0131caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_frames = []\n",
    "\n",
    "augmented, augmented_keypoints = apply_transform(transform, all_frames[0])\n",
    "replay_params = augmented[\"replay\"]\n",
    "aug_frames.append(augmented_keypoints)\n",
    "\n",
    "for frame_keypoints in tqdm(all_frames[1:]):\n",
    "    xy = [(np.max((pt[0], 0)), np.max((pt[1], 0))) for pt in frame_keypoints]\n",
    "    \n",
    "    augmented = A.ReplayCompose.replay(\n",
    "        replay_params,\n",
    "        image=np.zeros((256, 256)),\n",
    "        keypoints=xy,\n",
    "        keypoint_params=A.KeypointParams(format='xy', remove_invisible=False)\n",
    "    )\n",
    "\n",
    "    augmented_keypoints = np.array([[kp[0], kp[1]] for kp in augmented['keypoints']])\n",
    "\n",
    "    # Appending z axis data to the augmented dataset\n",
    "    augmented_keypoints = np.stack(\n",
    "        [augmented_keypoints[:, 0], augmented_keypoints[:, 1], frame_keypoints[:, 2]],\n",
    "        axis=-1\n",
    "    )\n",
    "\n",
    "    # keypoints_aug[:, :2] /= [256, 256]\n",
    "\n",
    "    aug_frames.append(augmented_keypoints)\n",
    "\n",
    "aug_frames = np.array(aug_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4553d710",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28f014f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xy[1], augmented_keypoints[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d64f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_frames.shape, aug_frames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6da826",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.visualize import get_pts_to_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d0e249",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = get_pts_to_img(augmented_keypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba645890",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_keypoints[:, :2] /= [256, 256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346e00bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_frames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4082a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf7b639",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e51d99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_frames = np.array(augmented[\"keypoints\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a45b03",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for r, a in zip(all_frames, aug_frames):\n",
    "    img = get_pts_to_img(r)\n",
    "    aug_img = get_pts_to_img(a)\n",
    "    plt.figure()\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    axs[0].imshow(img)\n",
    "    axs[1].imshow(aug_img)\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "    if i>=1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f823e1",
   "metadata": {},
   "source": [
    "Horizontal flip EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03476ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "TOTAL_PTS = 543"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead3361d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_frames = np.load(\"./data/generated/np_landmarks/100015657.npy\")\n",
    "all_frames = np.resize(all_frames, (all_frames.shape[0], TOTAL_PTS, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a15146f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.visualize import get_pts_to_img\n",
    "from src.augmentations import hflip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9c5511",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_frames = hflip(all_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cdb805",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.augmentations import KeypointsNonFlatIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd888a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx, iax = 4, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21088dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = all_frames.copy()\n",
    "\n",
    "data[:, :, 0] = 1 - data[:, :, 0]\n",
    "aug_frames = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8db33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_frames[idx][KeypointsNonFlatIndex.right_hand, iax], all_frames[idx][KeypointsNonFlatIndex.left_hand, iax]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaaf58a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_frames[idx][KeypointsNonFlatIndex.pose_right_hand, iax],\\\n",
    "all_frames[idx][KeypointsNonFlatIndex.pose_left_hand, iax]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e6d147",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_frames[idx][KeypointsNonFlatIndex.pose_right_hand, iax],\\\n",
    "aug_frames[idx][KeypointsNonFlatIndex.pose_left_hand, iax]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7413a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_frames[idx][KeypointsNonFlatIndex.right_hand, iax], aug_frames[idx][KeypointsNonFlatIndex.left_hand, iax]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296a8688",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for r, a in zip(all_frames, aug_frames):\n",
    "    img = get_pts_to_img(r)\n",
    "    aug_img = get_pts_to_img(a)\n",
    "\n",
    "    plt.figure()\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    axs[0].imshow(img)\n",
    "    axs[1].imshow(aug_img)\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "    if i>=10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e4f2f7",
   "metadata": {},
   "source": [
    "Limited keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b24df2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.visualize import get_pts_to_img\n",
    "from src.augmentations import hflip\n",
    "from src.keypoints import KeypointsNonFlatIndex\n",
    "\n",
    "TOTAL_PTS = 543"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa95cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_frames = np.load(\"./data/generated/np_landmarks/100015657.npy\")\n",
    "all_frames = np.where(np.isnan(all_frames), 0, all_frames)\n",
    "all_frames = np.resize(all_frames, (all_frames.shape[0], TOTAL_PTS, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d54c664",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_frames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae4f962",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_frames = all_frames[\n",
    "    :, list(KeypointsNonFlatIndex.lips) + list(KeypointsNonFlatIndex.eyes) + list(KeypointsNonFlatIndex.pose) + \n",
    "    list(KeypointsNonFlatIndex.left_hand) + list(KeypointsNonFlatIndex.right_hand), :\n",
    "]\n",
    "\n",
    "print(all_frames.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7dde25",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = get_pts_to_img(all_frames[43])\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b8c978",
   "metadata": {},
   "source": [
    "Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af80081",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9ca992",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = []\n",
    "class_labels += [\"face\"]*len(KeypointsNonFlatIndex.face)\n",
    "class_labels += [\"left_hand\"]*len(KeypointsNonFlatIndex.left_hand)\n",
    "class_labels += [\"pose\"]*len(KeypointsNonFlatIndex.pose)\n",
    "class_labels += [\"right_hand\"]*len(KeypointsNonFlatIndex.right_hand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78123806",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_for_alb=all_frames.shape[0]\n",
    "targets_for_alb=[f'keypoints{i}' for i in range(1, targets_for_alb)]\n",
    "targets_for_alb=dict.fromkeys(targets_for_alb, 'keypoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff56e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = A.Compose([\n",
    "        A.Rotate(limit=20, p=1),\n",
    "        A.RandomScale(scale_limit=(-1, 0.3), p=1),\n",
    "        A.Affine(translate_percent=(0.01, 0.1), p=1)\n",
    "    ],\n",
    "    keypoint_params=A.KeypointParams(\n",
    "        format='xy',\n",
    "        remove_invisible=False\n",
    "    ), \n",
    "    additional_targets=targets_for_alb\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae6e1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting negative value points to 0\n",
    "all_frames_tfmd = np.maximum(all_frames, 0)\n",
    "# Multiplying by 512 for albumentations to work properly\n",
    "all_frames_tfmd = all_frames * 512\n",
    "\n",
    "xy = all_frames_tfmd[:, :, :2]\n",
    "print(xy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141980e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "keypointsxy = xy.shape[0]\n",
    "keypointsxy = [f'keypoints{i}' for i in range(1, keypointsxy)]\n",
    "keypointsxy = dict.fromkeys(keypointsxy, None)\n",
    "\n",
    "for k, v in zip(keypointsxy.keys(), xy[1:, :, :]):\n",
    "    keypointsxy[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0737c825",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "augmented = transform(\n",
    "    image=np.zeros((512, 512)),\n",
    "    keypoints=xy[0],\n",
    "    **keypointsxy\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a22f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_augmented_keypoints = []\n",
    "i = 0\n",
    "for k, v in augmented.items():\n",
    "    if \"keypoints\" in k:\n",
    "        temp = np.array(v)\n",
    "        temp = np.stack(\n",
    "            [temp[:, 0], temp[:, 1], all_frames_tfmd[i, :, 2]],\n",
    "            axis=-1\n",
    "        )\n",
    "        all_augmented_keypoints.append(temp)\n",
    "        \n",
    "all_augmented_keypoints = np.array(all_augmented_keypoints)\n",
    "all_augmented_keypoints /= 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7654a495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmented = transform(image=np.zeros((512, 512)), keypoints=xy)\n",
    "augmented_keypoints = np.array(augmented[\"keypoints\"])\n",
    "augmented_keypoints = np.stack(\n",
    "    [augmented_keypoints[:, 0], augmented_keypoints[:, 1], all_frames_tfmd[0, :, 2]],\n",
    "    axis=-1\n",
    ")\n",
    "\n",
    "# Scaling back for plotting\n",
    "augmented_keypoints /= 512\n",
    "print(augmented_keypoints.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca59356",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "for img1, img2 in zip(all_frames, all_augmented_keypoints):\n",
    "    img = get_pts_to_img(img1)\n",
    "    aug_img = get_pts_to_img(img2)\n",
    "\n",
    "    plt.figure()\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    axs[0].imshow(img)\n",
    "    axs[1].imshow(aug_img)\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "    if i>=10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6fc171",
   "metadata": {},
   "source": [
    "Numpy augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc71bc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define augmentations\n",
    "image_width, image_height = 512, 512\n",
    "\n",
    "# Rotation degree\n",
    "angle = np.radians(90)\n",
    "cos = np.cos(angle)\n",
    "sin = np.sin(angle)\n",
    "rotation_matrix = np.array([[cos, -sin], [sin, cos]])\n",
    "\n",
    "# Scaling factor\n",
    "scale_factor = 0.5\n",
    "scaling_matrix = np.eye(2) * scale_factor\n",
    "\n",
    "# Center the keypoints\n",
    "center_point = np.array([image_width/2, image_height/2])\n",
    "keypoints_centered = all_frames_tfmd[:, :, :2] - center_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341c6a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmented_keypoints = np.dot(keypoints_centered, rotation_matrix.T)\n",
    "augmented_keypoints = np.dot(keypoints_centered, scaling_matrix.T)\n",
    "\n",
    "\n",
    "# Add center point coordinates back to all keypoints\n",
    "augmented_keypoints = augmented_keypoints + center_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88141db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_keypoints = np.stack([\n",
    "    augmented_keypoints[:, :, 0],\n",
    "    augmented_keypoints[:, :, 1],\n",
    "    all_frames_tfmd[:, :, 2]\n",
    "], axis = -1)\n",
    "\n",
    "augmented_keypoints /= 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591ba7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "for img1, img2 in zip(all_frames, augmented_keypoints):\n",
    "    img = get_pts_to_img(img1)\n",
    "    aug_img = get_pts_to_img(img2)\n",
    "\n",
    "    plt.figure()\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    axs[0].imshow(img)\n",
    "    axs[1].imshow(aug_img)\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "    if i>=10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f07a86",
   "metadata": {},
   "source": [
    "Flipping hand pose\n",
    "\n",
    "[left hand x 3, right hand x3]\n",
    "x-axis -> [20, 21, 22, 0, 0, 0]\n",
    "img width flip (50)\n",
    "\n",
    "x-axis -> [30, 29, 28, 50, 50, 50]\n",
    "\n",
    "final -> [50, 50, 50, 30, 29, 28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8276729",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "TOTAL_PTS = 543\n",
    "\n",
    "from src.visualize import get_pts_to_img\n",
    "from src.augmentations import hflip\n",
    "from src.keypoints import KeypointsNonFlatIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c161d7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_frames = np.load(\"./data/generated/np_landmarks/100015657.npy\")\n",
    "all_frames = np.where(np.isnan(all_frames), 0, all_frames)\n",
    "all_frames = np.resize(all_frames, (all_frames.shape[0], TOTAL_PTS, 3))\n",
    "\n",
    "all_frames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f041d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = data[\n",
    "    :, list(KeypointsNonFlatIndex.pose_right_hand), :\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf3b25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = all_frames[\n",
    "    :, list(KeypointsNonFlatIndex.pose_left_hand)\\\n",
    "    + list(KeypointsNonFlatIndex.pose_right_hand), :\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852c2975",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = get_pts_to_img(tmp[0])\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c54f78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = all_frames.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8d521b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rh = np.argwhere(data[0, :, 0] > 0.5)\n",
    "lh = np.argwhere(data[0, :, 0] <= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f39a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpx, tmpy, tmpz = data[0, rh, 0], data[0, rh, 1], data[0, rh, 2]\n",
    "\n",
    "data[0, rh, 0] = 1 - data[0, lh, 0]\n",
    "data[0, lh, 0] = 1 - tmpx\n",
    "\n",
    "data[0, rh, 1] = data[0, lh, 1]\n",
    "data[0, lh, 1] = tmpy\n",
    "\n",
    "data[0, rh, 2] = data[0, lh, 2]\n",
    "data[0, lh, 2] = tmpz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7467bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439415b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f547f587",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "x_pts_rh, y_pts_rh, z_pts_rh = data[:, KeypointsNonFlatIndex.right_hand, 0], \\\n",
    "    data[:, KeypointsNonFlatIndex.right_hand, 1], \\\n",
    "    data[:, KeypointsNonFlatIndex.right_hand, 2]\n",
    "\n",
    "x_pts_lh, y_pts_lh, z_pts_lh = data[:, KeypointsNonFlatIndex.left_hand, 0], \\\n",
    "    data[:, KeypointsNonFlatIndex.left_hand, 1], \\\n",
    "    data[:, KeypointsNonFlatIndex.left_hand, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dbdc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[:, KeypointsNonFlatIndex.right_hand, 0] = 1 - x_pts_lh\n",
    "data[:, KeypointsNonFlatIndex.left_hand, 0] = 1 - x_pts_rh\n",
    "\n",
    "data[:, KeypointsNonFlatIndex.right_hand, 1] = y_pts_lh\n",
    "data[:, KeypointsNonFlatIndex.left_hand, 1] = y_pts_rh\n",
    "\n",
    "data[:, KeypointsNonFlatIndex.right_hand, 2] = z_pts_lh\n",
    "data[:, KeypointsNonFlatIndex.left_hand, 2] = z_pts_rh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9342d8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0, KeypointsNonFlatIndex.right_hand, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3761264",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0, KeypointsNonFlatIndex.left_hand, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2df72ac",
   "metadata": {},
   "source": [
    "Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98ee18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d9fa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
    "        self.add = tf.keras.layers.Add()\n",
    "        self.normalize = tf.keras.layers.Normalization()\n",
    "\n",
    "class GlobalSelfAttention(BaseAttention):\n",
    "    def __call__(self, x):\n",
    "        attn_output = self.mha(\n",
    "            query=x,\n",
    "            value=x,\n",
    "            key=x\n",
    "        )\n",
    "\n",
    "#         x = self.add([x, attn_output])\n",
    "        x = self.normalize(attn_output)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26d3383",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (32, 294)\n",
    "model_input = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "x = GlobalSelfAttention(num_heads=4, key_dim=128, output_shape=128, dropout=0.25)(model_input)\n",
    "x = tf.keras.layers.Dense(128, activation=\"relu\")(x)\n",
    "x = tf.keras.layers.Dropout(0.25)(x)\n",
    "x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "\n",
    "output = tf.keras.layers.Dense(250, activation=\"softmax\")(x)\n",
    "\n",
    "model = tf.keras.Model(model_input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905d29e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=3e-4),\n",
    "    metrics=[tf.keras.metrics.CategoricalAccuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b1d589",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9baf07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_heads = 2\n",
    "input_n = 32\n",
    "input_dim = 1629\n",
    "key_dim = 128\n",
    "output_shape = 128\n",
    "\n",
    "total_params = 0\n",
    "# query, key, value projection\n",
    "total_params += 3 * (input_dim*key_dim + key_dim)\n",
    "print(total_params)\n",
    "# total heads\n",
    "total_params *= num_heads\n",
    "print(total_params)\n",
    "# downsclaing\n",
    "total_params += key_dim*num_heads*output_shape + output_shape\n",
    "print(total_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13150afe",
   "metadata": {},
   "source": [
    "Verfifying data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c8c65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_generator import GISLRSequence\n",
    "import src.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2bdcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dataset_path = \"./data/generated/np_landmarks/\"\n",
    "class_path = \"./data/raw/train.csv\"\n",
    "class_to_label_path = \"./data/raw/sign_to_prediction_index_map.json\"\n",
    "val_participants = [55372, 61333, 62590]\n",
    "test_participants = [30680, 37779, 2044]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c453abbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = utils.get_train_dataset(\n",
    "    save_dataset_path=save_dataset_path,\n",
    "    class_path=class_path,\n",
    "    class_to_label_path=class_to_label_path\n",
    ")\n",
    "\n",
    "df = utils.get_example_set(\n",
    "    df, test_participants=test_participants, val_participants=val_participants\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df78bca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = GISLRSequence(\n",
    "    df[df.example_set == \"train\"],\n",
    "    x_col=\"save_dataset_path\",\n",
    "    y_col=\"y_label\",\n",
    "    sample_size=32,\n",
    "    batch_size=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3bdd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in train_dataset:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7079e2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.raw_data_manipulation.visualize import get_pts_to_img\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bd9083",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for elem in x[0]:\n",
    "    plt.figure()\n",
    "    img = get_pts_to_img(np.resize(elem, (543, 3)))\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70f1e85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "69ae61b810ccd068109cf46e2c7efcb9e0e6b654af094ddbe91adfedfdc7d8f0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
