{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "772795d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/pb/8lqj234j0mx0kb6_vrtxc98m0000gn/T/ipykernel_20701/810824638.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmediapipe\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import mediapipe as mp\n",
    "\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "\n",
    "mp_holistic = mp.solutions.holistic\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(\"INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b710d67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "connections_type = dict(\n",
    "    face=mp_holistic.FACE_CONNECTIONS,\n",
    "    left_hand=mp_holistic.HAND_CONNECTIONS,\n",
    "    right_hand=mp_holistic.HAND_CONNECTIONS,\n",
    "    pose=mp_holistic.POSE_CONNECTIONS\n",
    ")\n",
    "\n",
    "IMG_SIZE = (512, 512, 3)\n",
    "VAL_SIZE = 0.2\n",
    "\n",
    "train_dataset_path = \"train_landmark_files/\"\n",
    "save_dataset_path = \"transformed_imgs/\"\n",
    "class_path = \"train.csv\"\n",
    "class_to_label_path = \"sign_to_prediction_index_map.json\"\n",
    "train_data_with_label = \"train_data_with_label.csv\"\n",
    "\n",
    "df = pd.read_csv(train_data_with_label)\n",
    "df = df.sample(frac = 1.0)\n",
    "\n",
    "val_df = df.iloc[0:int(np.floor(df.shape[0] * VAL_SIZE)), :]\n",
    "train_df = df.iloc[int(np.floor(df.shape[0] * VAL_SIZE)):df.shape[0], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d60c6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASLModel():\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_classes:int,\n",
    "        pretrained_model:str=\"mobilenet_v3\",\n",
    "        input_shape:tuple=None,\n",
    "        load_weights:bool=True\n",
    "    ) -> None:\n",
    "        logger.info(f\"Loading {pretrained_model} pre-trained model\")\n",
    "        \n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        if pretrained_model == 'mobilenet':\n",
    "            self.base = tf.keras.applications.MobileNetV2(\n",
    "                weights='imagenet' if load_weights else None,\n",
    "                include_top=False,\n",
    "                input_shape=input_shape,\n",
    "            )\n",
    "\n",
    "        elif pretrained_model == 'mobilenet_v3':\n",
    "            self.base = tf.keras.applications.MobileNetV3Small(\n",
    "                weights='imagenet' if load_weights else None,\n",
    "                include_top=False,\n",
    "                input_shape=input_shape,\n",
    "                pooling='avg',\n",
    "                minimalistic=True\n",
    "            )\n",
    "\n",
    "        elif pretrained_model == 'resnet':\n",
    "            self.base = tf.keras.applications.ResNet152V2(\n",
    "                weights='imagenet' if load_weights else None,\n",
    "                include_top=False,\n",
    "                input_shape=input_shape\n",
    "            )\n",
    "\n",
    "        elif pretrained_model == 'efficientnet':\n",
    "            self.base = tf.keras.applications.EfficientNetB7(\n",
    "                weights='imagenet' if load_weights else None,\n",
    "                include_top=False,\n",
    "                input_shape=input_shape,\n",
    "            )\n",
    "\n",
    "        elif pretrained_model == 'efficientnet_v2':\n",
    "            self.base = tf.keras.applications.EfficientNetV2S(\n",
    "                weights='imagenet' if load_weights else None,\n",
    "                include_top=False,\n",
    "                input_shape=input_shape,\n",
    "            )\n",
    "\n",
    "        self.base.trainable = False if load_weights else True\n",
    "        inputs = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "        self.model = tf.keras.Sequential()\n",
    "        self.model.add(inputs)\n",
    "        self.model.add(self.base)\n",
    "\n",
    "    def _initialize_network(self) -> tf.keras.Model:\n",
    "        \"\"\"\n",
    "        Initializes the network on top of pre-trained model\n",
    "\n",
    "        :params:\n",
    "            None\n",
    "\n",
    "        :returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        self.model.add(tf.keras.layers.Flatten())\n",
    "        self.model.add(tf.keras.layers.Dense(512, activation = 'relu'))\n",
    "        self.model.add(tf.keras.layers.BatchNormalization())\n",
    "        self.model.add(tf.keras.layers.Dropout(0.5))\n",
    "        self.model.add(tf.keras.layers.Dense(\n",
    "            self.n_classes, activation = 'softmax'\n",
    "        ))\n",
    "        self.model.add(tf.keras.layers.Softmax())\n",
    "\n",
    "    def get_model(self) -> tf.keras.Model:\n",
    "        \"\"\"\n",
    "        Compiles the model and return it\n",
    "\n",
    "        :params:\n",
    "            None\n",
    "\n",
    "        :returns:\n",
    "            {tf.keras.Model}\n",
    "        \"\"\"\n",
    "        self._initialize_network()\n",
    "\n",
    "        self.model.compile(\n",
    "            optimizer='adam',\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=[\n",
    "                'acc'\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        logger.info(f\"{self.model.summary()}\")\n",
    "\n",
    "        return self.model\n",
    "\n",
    "    def finetune_model(self, learning_rate: float = 1e-5):\n",
    "        \"\"\"\n",
    "        Compiles the model for finetuning and returns it.\n",
    "        Please make sure that model is trained first before finetuning the pretrained model\n",
    "\n",
    "        Reference: https://keras.io/guides/transfer_learning/#do-a-round-of-finetuning-of-the-entire-model\n",
    "\n",
    "        :params:\n",
    "            learning_rate {float}       -- Learning rate to be used while\n",
    "            finetuning the model. Needs to be low so that the pre-trained model\n",
    "            weights don't blow up\n",
    "\n",
    "        :returns:\n",
    "            {tf.keras.Model}\n",
    "        \"\"\"\n",
    "        self.base.trainable = True\n",
    "\n",
    "        self.model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=[\n",
    "                'acc',\n",
    "                tf.keras.metrics.TrueNegatives(),\n",
    "                tf.keras.metrics.FalsePositives(),\n",
    "                tf.keras.metrics.FalseNegatives(),\n",
    "                tf.keras.metrics.TruePositives()\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        logger.info(f\"{self.model.summary()}\")\n",
    "\n",
    "        return self.model\n",
    "\n",
    "    @property\n",
    "    def classifier(self):\n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ce626f",
   "metadata": {},
   "outputs": [],
   "source": [
    "asl_detector = ASLModel(\n",
    "    n_classes = df.y_label.nunique(),\n",
    "    input_shape = IMG_SIZE\n",
    ")\n",
    "\n",
    "model = asl_detector.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2af059",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GISLRSequence(tf.keras.utils.Sequence):\n",
    "    def __init__(self, df: pd.DataFrame, x_col: str, y_col: str, batch_size: int, shuffle: bool = True) -> None:\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "        self.x_files_path = df[x_col]\n",
    "        self.y = df[y_col]\n",
    "        \n",
    "        self.nframes = df.nframes\n",
    "        self.indices = df.index.to_list()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return (self.nframes.sum() // self.batch_size)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        subset = self.indices[(idx * self.batch_size):((idx + 1) * self.batch_size)]\n",
    "        batch_x = self.x_files_path[subset]\n",
    "        batch_y = self.y[subset]\n",
    "\n",
    "        X, y = self._get_data(batch_x, batch_y)\n",
    "\n",
    "        return X, y\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "    \n",
    "    def _get_data(self, batch_x, batch_y):\n",
    "        temp_X, temp_y = [], []\n",
    "\n",
    "        for idx, idy in zip(batch_x, batch_y):\n",
    "            temp = self._get_transformed_data(idx)\n",
    "\n",
    "            temp_X.append(temp)\n",
    "            temp_y.append(np.array(temp.shape[0] * [idy]))\n",
    "\n",
    "        if not temp_X:\n",
    "            return np.empty((0, 0, 0, 0), dtype=np.uint8), np.empty((0), dtype=np.uint8)\n",
    "            \n",
    "        x = temp_X[0]\n",
    "        y = temp_y[0]\n",
    "        \n",
    "        for i, elem in enumerate(zip(temp_X, temp_y)):\n",
    "            if i == 0:\n",
    "                continue\n",
    "\n",
    "            x = np.concatenate((x, elem[0]))\n",
    "            y = np.concatenate((y, elem[1]))\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    def _get_pts_to_img(self, data: pd.DataFrame) -> np.ndarray:\n",
    "        image = np.zeros(IMG_SIZE, np.uint8)\n",
    "\n",
    "        pts = {\n",
    "            \"face\": [],\n",
    "            \"left_hand\": [],\n",
    "            \"right_hand\": [],\n",
    "            \"pose\": []\n",
    "        }\n",
    "\n",
    "        for elem in data.itertuples():\n",
    "            pts[elem.type].append(\n",
    "                landmark_pb2.NormalizedLandmark(\n",
    "                    x=elem.x,\n",
    "                    y=elem.y,\n",
    "                    z=elem.z,\n",
    "                    visibility=1.0\n",
    "                )\n",
    "            )\n",
    "\n",
    "        for body_part, landmarks in pts.items():\n",
    "            landmark_subset = landmark_pb2.NormalizedLandmarkList(landmark =  landmarks)\n",
    "\n",
    "            mp.solutions.drawing_utils.draw_landmarks(\n",
    "                image,\n",
    "                landmark_subset,\n",
    "                connections_type[body_part]\n",
    "            )\n",
    "\n",
    "        return image\n",
    "\n",
    "    def _get_transformed_data(self, dataset_file_path) -> np.ndarray:\n",
    "        df = pd.read_parquet(dataset_file_path)\n",
    "        logger.info(f\"Found: {df.frame.nunique()} frames in {dataset_file_path}\")\n",
    "\n",
    "        all_imgs = []\n",
    "\n",
    "        for single_frame in df.frame.unique():\n",
    "            temp = df[df.frame == single_frame]\n",
    "            single_frame_img = self._get_pts_to_img(temp)\n",
    "            all_imgs.append(single_frame_img)\n",
    "\n",
    "        return np.array(all_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2a66f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = GISLRSequence(\n",
    "    train_df,\n",
    "    x_col = \"filename\",\n",
    "    y_col = \"y_label\",\n",
    "    batch_size = 16\n",
    ")\n",
    "\n",
    "val_dataset = GISLRSequence(\n",
    "    val_df,\n",
    "    x_col = \"filename\",\n",
    "    y_col = \"y_label\",\n",
    "    batch_size = 16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9b3816",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    dataset,\n",
    "    epochs=12,\n",
    "    verbose=1,\n",
    "    validation_data=val_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370707c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
