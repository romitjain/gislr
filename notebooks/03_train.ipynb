{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "772795d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(\"INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b710d67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "IMG_SIZE = (512, 512, 3)\n",
    "VAL_SIZE = 0.2\n",
    "\n",
    "train_dataset_path = \"train_landmark_files/\"\n",
    "save_dataset_path = \"transformed_imgs/\"\n",
    "class_path = \"train.csv\"\n",
    "class_to_label_path = \"sign_to_prediction_index_map.json\"\n",
    "train_data_with_label = \"train_data_with_label.csv\"\n",
    "\n",
    "df = pd.read_csv(train_data_with_label)\n",
    "df = df.sample(frac = 1.0)\n",
    "n_classes = df.y_label.nunique()\n",
    "\n",
    "val_df = df.iloc[0:int(np.floor(df.shape[0] * VAL_SIZE)), :]\n",
    "train_df = df.iloc[int(np.floor(df.shape[0] * VAL_SIZE)):df.shape[0], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fe2af059",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GISLRSequence(tf.keras.utils.Sequence):\n",
    "    def __init__(self, df: pd.DataFrame, x_col: str, y_col: str, sample_size: int, batch_size: int, shuffle: bool = True) -> None:\n",
    "        self.batch_size = batch_size\n",
    "        self.sample_size = sample_size\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "        self.x_files_path = df[x_col]\n",
    "        self.y = df[y_col]\n",
    "        \n",
    "        self.nframes = df.nframes\n",
    "        self.indices = df.index.to_list()\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.x_files_path) // self.batch_size)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        subset = self.indices[(idx * self.batch_size):((idx + 1) * self.batch_size)]\n",
    "        batch_x = self.x_files_path[subset]\n",
    "        batch_y = self.y[subset]\n",
    "\n",
    "        X, y = self._get_data(batch_x, batch_y)\n",
    "\n",
    "        return X, tf.one_hot(y, depth=n_classes)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "    def _get_data(self, batch_x, batch_y):\n",
    "        temp_X, temp_y = [], []\n",
    "\n",
    "        for idx, idy in zip(batch_x, batch_y):\n",
    "            temp = self._get_transformed_data(idx)\n",
    "\n",
    "            temp_X.append(temp)\n",
    "            temp_y.append(idy)\n",
    "\n",
    "        return np.array(temp_X), np.array(temp_y)\n",
    "\n",
    "    def _get_transformed_data(self, dataset_file_path) -> np.ndarray:\n",
    "        df = pd.read_parquet(dataset_file_path)\n",
    "        logger.info(f\"Found: {df.frame.nunique()} frames in {dataset_file_path}\")\n",
    "\n",
    "        all_imgs = []\n",
    "\n",
    "        sample_frames = df.frame.unique()[:self.sample_size]\n",
    "\n",
    "        for single_frame in sample_frames:\n",
    "            temp = df[(df.frame == single_frame)]\n",
    "            temp_feat = np.array(temp.loc[:, [\"x\", \"y\", \"z\"]])\n",
    "            temp_feat = temp_feat.reshape((temp.shape[0] * 3))\n",
    "            # temp_feat = np.where(np.isnan(temp_feat), 0, temp_feat)\n",
    "            all_imgs.append(temp_feat)\n",
    "\n",
    "        # if len(sample_frames) < self.sample_size:\n",
    "        #     for i in range(self.sample_size-len(sample_frames)):\n",
    "        #         all_imgs.append(np.zeros(temp.shape[0] * 3))\n",
    "\n",
    "        return np.array(all_imgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee2a66f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = GISLRSequence(\n",
    "    train_df.sample(20000),\n",
    "    x_col = \"filename\",\n",
    "    y_col = \"y_label\",\n",
    "    sample_size=32,\n",
    "    batch_size = 16\n",
    ")\n",
    "\n",
    "val_dataset = GISLRSequence(\n",
    "    val_df.sample(2000),\n",
    "    x_col = \"filename\",\n",
    "    y_col = \"y_label\",\n",
    "    sample_size=32,\n",
    "    batch_size = 16\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "441f4cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GISLRModelv1():\n",
    "    def __init__(self, input_shape = (32, 1629)):\n",
    "        model_input = tf.keras.Input(shape=input_shape)\n",
    "        dense = tf.keras.layers.Dense(128)(model_input)\n",
    "\n",
    "        value_input = dense\n",
    "\n",
    "        # CNN layer.\n",
    "        cnn_layer = tf.keras.layers.Conv1D(filters=512, kernel_size=4, padding='same')\n",
    "        query_seq_encoding = cnn_layer(value_input)\n",
    "        value_seq_encoding = cnn_layer(value_input)\n",
    "\n",
    "        query_value_attention_seq, attn_score = tf.keras.layers.Attention()([query_seq_encoding, value_seq_encoding], return_attention_scores=True)\n",
    "\n",
    "        query_encoding = tf.keras.layers.GlobalAveragePooling1D()(query_seq_encoding)\n",
    "        query_value_attention = tf.keras.layers.GlobalAveragePooling1D()(query_value_attention_seq)\n",
    "        query_concat = tf.keras.layers.Concatenate()([query_encoding, query_value_attention])\n",
    "\n",
    "        dense_attn = tf.keras.layers.Dense(512)(query_concat)\n",
    "        dropout = tf.keras.layers.Dropout(0.2)(dense_attn)\n",
    "\n",
    "        output = tf.keras.layers.Dense(n_classes, activation=\"softmax\")(dropout)\n",
    "        self.model = tf.keras.Model(model_input, output)\n",
    "\n",
    "    def get_model(self):\n",
    "        self.model.compile(\n",
    "            loss='categorical_crossentropy',\n",
    "            optimizer='adam',\n",
    "            metrics=[tf.keras.metrics.CategoricalAccuracy(), tf.keras.metrics.CategoricalCrossentropy()]\n",
    "        )\n",
    "        print(self.model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4adda8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c2c664dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
    "        self.layernorm = tf.keras.layers.LayerNormalization()\n",
    "        self.add = tf.keras.layers.Add()\n",
    "\n",
    "class GlobalSelfAttention(BaseAttention):\n",
    "    def call(self, x):\n",
    "        attn_output = self.mha(\n",
    "            query=x,\n",
    "            value=x,\n",
    "            key=x\n",
    "        )\n",
    "        # x = self.add([x, attn_output])\n",
    "        # x = self.layernorm(x)\n",
    "        return attn_output\n",
    "\n",
    "class GISLRModelv2():\n",
    "    def __init__(self, input_shape = (32, 1629)) -> None:\n",
    "        # Multi head attention\n",
    "        model_input = tf.keras.Input(shape=input_shape)\n",
    "        # CNN layer.\n",
    "        query_seq_encoding = tf.keras.layers.Conv1D(filters=128, kernel_size=4, padding='same')(model_input)\n",
    "\n",
    "        mha = GlobalSelfAttention(num_heads=2, key_dim=128)(query_seq_encoding)\n",
    "\n",
    "        # query_encoding = tf.keras.layers.GlobalAveragePooling1D()(query_seq_encoding)\n",
    "        query_value_attention = tf.keras.layers.GlobalAveragePooling1D()(mha)\n",
    "        # layernorm = tf.keras.layers.LayerNormalization()(query_value_attention)\n",
    "\n",
    "        dense_attn = tf.keras.layers.Dense(256, activation=\"relu\")(query_value_attention)\n",
    "        dropout = tf.keras.layers.Dropout(0.2)(dense_attn)\n",
    "\n",
    "        output = tf.keras.layers.Dense(n_classes, activation=\"softmax\")(dropout)\n",
    "\n",
    "        self.model = tf.keras.Model(model_input, output)\n",
    "\n",
    "    def get_model(self):\n",
    "        self.model.compile(\n",
    "            loss='categorical_crossentropy',\n",
    "            optimizer='adam',\n",
    "            metrics=[tf.keras.metrics.CategoricalAccuracy(), tf.keras.metrics.CategoricalCrossentropy()]\n",
    "        )\n",
    "        print(self.model.summary())\n",
    "\n",
    "        return self.model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f7c2855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         [(None, 32, 1629)]        0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 32, 128)           834176    \n",
      "_________________________________________________________________\n",
      "global_self_attention_8 (Glo (None, 32, 128)           131968    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_8 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 250)               64250     \n",
      "=================================================================\n",
      "Total params: 1,063,418\n",
      "Trainable params: 1,063,418\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = GISLRModelv2().get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbf6049",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a9b3816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "1250/1250 [==============================] - 683s 546ms/step - loss: 5.5409 - categorical_accuracy: 0.0043 - categorical_crossentropy: 5.5409 - val_loss: 5.5218 - val_categorical_accuracy: 0.0020 - val_categorical_crossentropy: 5.5218\n",
      "Epoch 2/12\n",
      "1250/1250 [==============================] - 814s 651ms/step - loss: 5.5199 - categorical_accuracy: 0.0048 - categorical_crossentropy: 5.5199 - val_loss: 5.5225 - val_categorical_accuracy: 0.0020 - val_categorical_crossentropy: 5.5225\n",
      "Epoch 3/12\n",
      "  29/1250 [..............................] - ETA: 16:54 - loss: 5.5175 - categorical_accuracy: 0.0043 - categorical_crossentropy: 5.5175"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-20a0fa7e75d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensorboard_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m )\n",
      "\u001b[0;32m~/.virtualenvs/fi/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/fi/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/fi/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/fi/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/fi/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/fi/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.virtualenvs/fi/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "log_dir = os.path.join(\"./logs/fit/\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M\"))\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=log_dir, histogram_freq=1\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=12,\n",
    "    verbose=1,\n",
    "    validation_data=val_dataset,\n",
    "    callbacks=[tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339128b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2f6cdae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = GISLRSequence(\n",
    "    train_df,\n",
    "    x_col=\"filename\",\n",
    "    y_col=\"y_label\",\n",
    "    sample_size=64,\n",
    "    batch_size=16\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d8af7062",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/romitjain/.virtualenvs/fi/lib/python3.7/site-packages/ipykernel_launcher.py:38: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    }
   ],
   "source": [
    "for x, y in test:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "baeb48eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54, 1629)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c5535e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "zz = pd.DataFrame(x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5abd97e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54, 1629)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zz.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9681723",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
